# -*- coding: utf-8 -*-
"""CNNCapstone.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1thl0jBPJmXhdsYJeRyRrkLfew_VVDkQS

# 1) Data Set Up and Importing
"""

#Importing Necessary Libraries
import tensorflow as tf
from tensorflow.keras import datasets, layers, models
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.models import Sequential
import matplotlib.pyplot as plt
import pandas as pd
import os
import cv2
import zipfile
import numpy as np
from matplotlib.image import imread

#Mounting Google drive to have access to data
from google.colab import drive
drive.mount('/content/drive')

#Using zipfile library in Python unzip the file with the data
#The first line will open the zip file so it can be read
zip_obj= zipfile.ZipFile('/content/drive/MyDrive/chestctscandataset.zip','r')
#This stores them in a temporary file directory
zip_obj.extractall('/tmp')
zip_obj.close()

"""## 2) Exploratory Data Analysis and Visualization"""

number_classes = {'Train': 613,
'Test':315,
'Valid': 72}

plt.bar(number_classes.keys(), number_classes.values(), width = .5);
for key, value in number_classes.items():
    plt.text(key, value + 0.1, str(value), ha='center', va='bottom', fontsize=8)
plt.title("Number of Images by in Each Dataset");
plt.xlabel('Set Name');
plt.ylabel('# Images');

test_classes = {'Adenocarcinoma': len(os.listdir('/tmp/Data/test/adenocarcinoma')),
'Large Cell Carcinoma': len(os.listdir('/tmp/Data/test/large.cell.carcinoma')),
'Squamous Cell Carcinoma': len(os.listdir('/tmp/Data/test/squamous.cell.carcinoma')),
'Normal': len(os.listdir('/tmp/Data/test/normal'))}
plt.bar(test_classes.keys(), test_classes.values(), width = .5);
for key, value in test_classes.items():
    plt.text(key, value + 0.1, str(value), ha='center', va='bottom', fontsize=8)
plt.title("Number of Images by Class In Testing Set");
plt.xlabel('Class Names');
plt.ylabel('# Images');
plt.xticks(rotation=45, ha="right")

train_classes = {'Adenocarcinoma': len(os.listdir('/tmp/Data/train/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib')),
'Large Cell Carcinoma': len(os.listdir('/tmp/Data/train/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa')),
'Squamous Cell Carcinoma': len(os.listdir('/tmp/Data/train/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa')),
'Normal': len(os.listdir('/tmp/Data/train/normal'))}
plt.bar(train_classes.keys(), train_classes.values(), width = .5);
for key, value in train_classes.items():
    plt.text(key, value + 0.1, str(value), ha='center', va='bottom', fontsize=8)
plt.title("Number of Images by Class In Training Set");
plt.xlabel('Class Names');
plt.ylabel('# Images');
plt.xticks(rotation=45, ha="right")

valid_classes = {'Adenocarcinoma': len(os.listdir('/tmp/Data/valid/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib')),
'Large Cell Carcinoma': len(os.listdir('/tmp/Data/valid/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa')),
'Squamous Cell Carcinoma': len(os.listdir('/tmp/Data/valid/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa')),
'Normal': len(os.listdir('/tmp/Data/valid/normal'))}
plt.bar(valid_classes.keys(), valid_classes.values(), width = .5);
for key, value in valid_classes.items():
    plt.text(key, value + 0.1, str(value), ha='center', va='bottom', fontsize=8)
plt.title("Number of Images by Class In Validation Set");
plt.xlabel('Class Names');
plt.ylabel('# Images');
plt.xticks(rotation=45, ha="right")

"""Eigen Images"""

import os
import numpy as np
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from keras.preprocessing import image
from math import ceil

def img2np(path, list_of_filename, size=(64, 64)):
    full_mat = np.array([])  # Initialize an empty 1D array

    for fn in list_of_filename:
        fp = os.path.join(path, fn)
        current_image = image.load_img(fp, target_size=size, color_mode='grayscale')
        img_ts = image.img_to_array(current_image)
        # Concatenate the 1D array to the existing array
        full_mat = np.concatenate((full_mat, img_ts.ravel()))

    return full_mat

def eigenimages(full_mat, title, n_comp=0.7, size=(64, 64)):
    # Reshape the 1D array to a 2D array
    full_mat_2d = full_mat.reshape((-1, np.prod(size)))

    # fit PCA to describe n_comp * variability in the class
    pca = PCA(n_components=n_comp, whiten=True)
    pca.fit(full_mat_2d)
    print('Number of PC:', pca.n_components_)
    return pca

def plot_pca(pca, size=(64, 64)):
    # plot eigenimages in a grid
    n = pca.n_components_
    fig = plt.figure(figsize=(8, 8))
    r = int(n**.5)
    c = ceil(n / r)
    for i in range(n):
        ax = fig.add_subplot(r, c, i + 1, xticks=[], yticks=[])
        ax.imshow(pca.components_[i].reshape(size), cmap='Greys_r')
    plt.axis('off')
    plt.show()

# Specify the file directory
directory = '/tmp/Data/train/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib'

# Get a list of filenames in the directory
filenames = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]

# Run img2np on the directory
images = img2np(directory, filenames)

# Run eigenimages and plot_pca
pca_images = eigenimages(images, 'ADENOCARCINOMA')
plot_pca(pca_images)

import os
import numpy as np
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from keras.preprocessing import image

def img2np(path, list_of_filename, size=(64, 64)):
    full_mat = np.array([])  # Initialize an empty 1D array

    for fn in list_of_filename:
        fp = os.path.join(path, fn)
        current_image = image.load_img(fp, target_size=size, color_mode='grayscale')
        img_ts = image.img_to_array(current_image)
        # Concatenate the 1D array to the existing array
        full_mat = np.concatenate((full_mat, img_ts.ravel()))

    return full_mat

def eigenimages(full_mat, title, n_comp=0.7, size=(64, 64)):
    # Reshape the 1D array to a 2D array
    full_mat_2d = full_mat.reshape((-1, np.prod(size)))

    # fit PCA to describe n_comp * variability in the class
    pca = PCA(n_components=n_comp, whiten=True)
    pca.fit(full_mat_2d)
    print('Number of PC:', pca.n_components_)
    return pca

def plot_pca(pca, size=(64, 64)):
    # plot eigenimages in a grid
    n = pca.n_components_
    fig = plt.figure(figsize=(8, 8))
    r = int(n**.5)
    c = ceil(n / r)
    for i in range(n):
        ax = fig.add_subplot(r, c, i + 1, xticks=[], yticks=[])
        ax.imshow(pca.components_[i].reshape(size), cmap='Greys_r')
    plt.axis('off')
    plt.show()

# Specify the file directory
directory = '/tmp/Data/train/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa'

# Get a list of filenames in the directory
filenames = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]

# Run img2np on the directory
images = img2np(directory, filenames)

# Run eigenimages and plot_pca
pca_images = eigenimages(images, 'ADENOCARCINOMA')
plot_pca(pca_images)

import os
import numpy as np
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from keras.preprocessing import image

def img2np(path, list_of_filename, size=(64, 64)):
    full_mat = np.array([])  # Initialize an empty 1D array

    for fn in list_of_filename:
        fp = os.path.join(path, fn)
        current_image = image.load_img(fp, target_size=size, color_mode='grayscale')
        img_ts = image.img_to_array(current_image)
        # Concatenate the 1D array to the existing array
        full_mat = np.concatenate((full_mat, img_ts.ravel()))

    return full_mat

def eigenimages(full_mat, title, n_comp=0.7, size=(64, 64)):
    # Reshape the 1D array to a 2D array
    full_mat_2d = full_mat.reshape((-1, np.prod(size)))

    # fit PCA to describe n_comp * variability in the class
    pca = PCA(n_components=n_comp, whiten=True)
    pca.fit(full_mat_2d)
    print('Number of PC:', pca.n_components_)
    return pca

def plot_pca(pca, size=(64, 64)):
    # plot eigenimages in a grid
    n = pca.n_components_
    fig = plt.figure(figsize=(8, 8))
    r = int(n**.5)
    c = ceil(n / r)
    for i in range(n):
        ax = fig.add_subplot(r, c, i + 1, xticks=[], yticks=[])
        ax.imshow(pca.components_[i].reshape(size), cmap='Greys_r')
    plt.axis('off')
    plt.show()

# Specify the file directory
directory = '/tmp/Data/train/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa'

# Get a list of filenames in the directory
filenames = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]

# Run img2np on the directory
images = img2np(directory, filenames)

# Run eigenimages and plot_pca
pca_images = eigenimages(images, 'ADENOCARCINOMA')
plot_pca(pca_images)

import os
import numpy as np
from sklearn.decomposition import PCA
import matplotlib.pyplot as plt
from keras.preprocessing import image

def img2np(path, list_of_filename, size=(64, 64)):
    full_mat = np.array([])  # Initialize an empty 1D array

    for fn in list_of_filename:
        fp = os.path.join(path, fn)
        current_image = image.load_img(fp, target_size=size, color_mode='grayscale')
        img_ts = image.img_to_array(current_image)
        # Concatenate the 1D array to the existing array
        full_mat = np.concatenate((full_mat, img_ts.ravel()))

    return full_mat

def eigenimages(full_mat, title, n_comp=0.7, size=(64, 64)):
    # Reshape the 1D array to a 2D array
    full_mat_2d = full_mat.reshape((-1, np.prod(size)))

    # fit PCA to describe n_comp * variability in the class
    pca = PCA(n_components=n_comp, whiten=True)
    pca.fit(full_mat_2d)
    print('Number of PC:', pca.n_components_)
    return pca

def plot_pca(pca, size=(64, 64)):
    # plot eigenimages in a grid
    n = pca.n_components_
    fig = plt.figure(figsize=(8, 8))
    r = int(n**.5)
    c = ceil(n / r)
    for i in range(n):
        ax = fig.add_subplot(r, c, i + 1, xticks=[], yticks=[])
        ax.imshow(pca.components_[i].reshape(size), cmap='Greys_r')
    plt.axis('off')
    plt.show()

# Specify the file directory
directory = '/tmp/Data/train/normal'

# Get a list of filenames in the directory
filenames = [f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))]

# Run img2np on the directory
images = img2np(directory, filenames)

# Run eigenimages and plot_pca
pca_images = eigenimages(images, 'ADENOCARCINOMA')
plot_pca(pca_images)

"""## 3) Data Profiling and Preparation"""

#Now that we have access to the data, we can see how many images are in each one
#Assignment 2 wants number of rows, columns, years
#Describe the training set, test set, and validation set
#Using os we can access file structures and images inside of them

#Counting the total number of images within the entire datset

imagefile_count = sum(len(files) for _, _, files in os.walk(r'/tmp/Data'))
print(imagefile_count)

#Print How Many Images of each class are In Test Files
print('Test Set Files:', len(os.listdir('/tmp/Data/test')))
print('Adenocarcinoma Test Images:', len(os.listdir('/tmp/Data/test/adenocarcinoma')))
print('Large Cell Carcinoma Test Images:', len(os.listdir('/tmp/Data/test/large.cell.carcinoma')))
print('Squamous Cell Carcinoma Test Images:',len(os.listdir('/tmp/Data/test/squamous.cell.carcinoma')))
print('Normal Test Images:', len(os.listdir('/tmp/Data/test/normal')))

#Print How many Images of Each class are in the Train Files
print('\n\n Train Set Files:', len(os.listdir('/tmp/Data/train')))
print('Adenocarcinoma Train Images:', len(os.listdir('/tmp/Data/train/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib')))
print('Large Cell Carcinoma Train Images:', len(os.listdir('/tmp/Data/train/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa')))
print('Squamous Cell Carcinoma Train Images:',len(os.listdir('/tmp/Data/train/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa')))
print('Normal Train Images:', len(os.listdir('/tmp/Data/train/normal')))


#Print How many Images of Each class are in the Validation Files
print('\n\n Validation Set Files:', len(os.listdir('/tmp/Data/valid')))
print('Adenocarcinoma Valid Images:', len(os.listdir('/tmp/Data/valid/adenocarcinoma_left.lower.lobe_T2_N0_M0_Ib')))
print('Large Cell Carcinoma Valid Images:', len(os.listdir('/tmp/Data/valid/large.cell.carcinoma_left.hilum_T2_N2_M0_IIIa')))
print('Squamous Cell Carcinoma Valid Images:',len(os.listdir('/tmp/Data/valid/squamous.cell.carcinoma_left.hilum_T1_N2_M0_IIIa')))
print('Normal Valid Images:', len(os.listdir('/tmp/Data/valid/normal')))

#Lets see the dimensions we are working with in the dataset.
#As a test we will print dimensions from the normal test images

folder_path = "/tmp/Data/test/normal"

image_dimensions = []

for file in os.listdir(folder_path):
    if file.endswith(".jpg") or file.endswith(".png"):
        # Load the image using cv2
        image_path = os.path.join(folder_path, file)
        image = cv2.imread(image_path)
        dimensions = image.shape
        image_dimensions.append(dimensions)
    else:
      print('Cannot locate image path.')

# Convert the list of dimensions to a NumPy array
image_dimensions = np.array(image_dimensions)

print(image_dimensions)

#Now lets Prepare our Image Sizes using ImageGenerator
#We are going to use the target size 224x224 px so all the images are the same size
#We can also use ImageDataGenerator for image augmentation- lets run this model first w/o augmentation and see our results
#This might be useful for our small dataset so it does not overfit :)

train_datagen= ImageDataGenerator(rescale=1./255,
                                  horizontal_flip=True)

traindata_generator =train_datagen.flow_from_directory('/tmp/Data/train',
                                                                             target_size=(224,224),
                                                                             batch_size=32,
                                                                             class_mode='categorical',
                                                                             seed=145,
                                                                             shuffle= True
                                                                            )

testdata_generator = ImageDataGenerator(rescale=1./255).flow_from_directory('/tmp/Data/test',
                                                                             target_size=(224,224),
                                                                             batch_size=32,
                                                                             class_mode='categorical',
                                                                             seed=145
                                                                            )


validdata_generator = ImageDataGenerator(rescale=1./255).flow_from_directory('/tmp/Data/valid',
                                                                             target_size=(224,224),
                                                                             batch_size=32,
                                                                             class_mode='categorical',
                                                                             seed=145
                                                                            )

#This assigns train, test, validation variables to the data
X_train, y_train = next(traindata_generator)
X_test, y_test = next(testdata_generator)
X_val, y_val = next(validdata_generator)

"""# 4) Model Training"""

#Defining the Layering in The Model 1

model= Sequential()

model.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(224, 224, 3)))

model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Conv2D(64, (3, 3), activation='relu'))

model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Conv2D(128, (3, 3), activation='relu'))

model.add(layers.MaxPooling2D((2, 2)))

model.add(layers.Flatten())

model.add(Dense(128, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(4, activation='softmax'))

model.summary()

#Compiling the model and specifying the loss function, categorical cross entropy is chosen for multi-class classification
from tensorflow.keras import optimizers
model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

#Fitting the model and specifying that parameters for each epoch
history = model.fit(
    traindata_generator,
    validation_data=validdata_generator,
    epochs=15
     )

#Defining Arcitecture for Model 2

model1= Sequential()

model1.add(layers.Conv2D(32, (3, 3), activation='relu',input_shape=(224, 224, 3)))

model1.add(layers.Conv2D(32, (3, 3), activation='relu'))

model1.add(layers.MaxPooling2D((2, 2)))


model1.add(layers.Conv2D(32, (3, 3), activation='relu'))

model1.add(layers.MaxPooling2D((2, 2)))


model1.add(layers.Conv2D(64, (3, 3), activation='relu'))
model1.add(layers.Conv2D(64, (3, 3), activation='relu'))

model1.add(layers.MaxPooling2D((2, 2)))


model1.add(layers.Flatten())

model1.add(Dense(512, activation='relu'))
model1.add(Dropout(0.5))

model1.add(Dense(4, activation='softmax'))

model1.summary()

#Compiling the model
from tensorflow.keras import optimizers
model1.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

#Fitting the model over 15 epochs
history1 = model1.fit(
    traindata_generator,
    validation_data=validdata_generator,
    epochs=15,
     )

"""## Model Comparison

The following code was adapted from and inspired by Ariful Joy on Kaggle, who used similar modeling on this dataset. In this section I was inspired by his used of confusion matrices, val loss/training loss graphs, and val accuracy/training accuracy graphs.
https://www.kaggle.com/code/arifulislamjoy/cnns-on-chest-ct-scan
https://www.tutorialspoint.com/how-can-tensorflow-be-used-to-evaluate-a-cnn-model-using-python

Learning Curves Plot- Accuracy versus Training Loss
"""

#Plotting Model 1 accuracy metrics
#Specifying dictionaries for each value to be stored
history_dict = history.history

acc_values = history_dict['accuracy']
val_acc_values = history_dict['val_accuracy']
epochs = range(1, len(acc_values) + 1)

line1 = plt.plot(epochs, val_acc_values, label = 'Validation Accuracy')
line2 = plt.plot(epochs, acc_values, label = 'Training Accuracy')

plt.setp(line1, linewidth = 1.8, marker = 'o', markersize = 6.5)
plt.setp(line2, linewidth = 1.8, marker = '*', markersize = 8.0)
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Model 1 Accuracy Metrics')
plt.grid(True)
plt.legend()
plt.show()

#Plotting the loss charts

history_dict = history.history

loss_values = history_dict['loss']
val_loss_values = history_dict['val_loss']
epochs = range(1, len(loss_values) + 1)

line1 = plt.plot(epochs, val_loss_values, label = 'Validation Loss')
line2 = plt.plot(epochs, loss_values, label = 'Training Loss')

plt.setp(line1, linewidth = 1.8, marker = 'o', markersize = 6.0)
plt.setp(line2, linewidth = 1.5, marker = '*', markersize = 8.0)
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Model 1 Loss Metrics')
plt.grid(True)
plt.legend()
plt.show()

"""Model 2 Loss Metrics"""

# Model 2
#Plotting the loss charts

history_dict1 = history1.history

loss_values1 = history_dict1['loss']
val_loss_values1 = history_dict1['val_loss']
epochs1 = range(1, len(loss_values1) + 1)

line1 = plt.plot(epochs1, val_loss_values1, label='Validation Loss')
line2 = plt.plot(epochs1, loss_values1, label='Training Loss')

plt.setp(line1, linewidth=1.8, marker='o', markersize=6.0)
plt.setp(line2, linewidth=1.5, marker='*', markersize=8.0)
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Model 2 Loss Metrics')
plt.grid(True)
plt.legend()
plt.show()

#Model 2 Plotting Accuracy Metrics
history_dict1 = history1.history

acc_values1 = history_dict1['accuracy']
val_acc_values1 = history_dict1['val_accuracy']
epochs1 = range(1, len(acc_values) + 1)

line1 = plt.plot(epochs, val_acc_values1, label = 'Validation Accuracy')
line2 = plt.plot(epochs, acc_values1, label = 'Training Accuracy')

plt.setp(line1, linewidth = 1.8, marker = 'o', markersize = 6.5)
plt.setp(line2, linewidth = 1.8, marker = '*', markersize = 8.0)
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.title('Model 2 Accuracy Metrics')
plt.grid(True)
plt.legend()
plt.show()